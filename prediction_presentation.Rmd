---
title: "Predicting CO2 Emissions by Power Plant"
author: "Owen Jetton"
date: "3/10/2021"
output: ioslides_presentation
---



```{r setup, echo = F}
knitr::opts_chunk$set(echo = FALSE)
```




## The Big Picture 

```{r emissions graph, out.width= "65%", out.extra='style="float:right; padding:10px"'}
knitr::include_graphics("C:/Users/ojett/Documents/EC424/ec424project/project_markdown_files/figure-gfm/Initial_Graphs-1.png")
```

 <font size="4"> 
 **- Question:** How much carbon dioxide will a power plant emit in a year?  
 **- Relevance:** limiting atmospheric CO2 emissions to combat climate change.  
 **- This is a prediction problem** because it concerns estimating CO2 emissions from a power plant as opposed to the relation between CO2 emissions and other variables.

</font>

## Data

```{r gas graph, out.width= "65%", out.extra='style="float:right; padding:10px"'}
knitr::include_graphics("C:/Users/ojett/Documents/EC424/ec424project/project_markdown_files/figure-gfm/Initial_Graphs-2.png")
```
 <font size="3"> 
 **- Annual data** from 2016 to 2019.
 **- Sources:** *U.S. Energy Information Agency* and  *National Centers for Environmental Information*.  
 **- Example variables:** kilowatt hour generation, Residential Energy Demand Temperature Index (REDTI), aggregated fuel group, and quantity of fuel consumed.  
 **- Shortcomings:** annual emission timeframe, missing REDTI data for Hawaii and Alaska, and energy demand generalized by state.  
 **- Data cleaning** involved binding multiple dataframes together and renaming variables with long names such as "fuel_consumption_for_useful_thermal_output_mmbtu"

</font>


## Methods 

<font size="3">  

**Preparation:** used a tidymodels recipe that created dummy variables for all nominal predictors, computed mean imputation for all numerical predictors, removed all low-variance, highly correlated, and linearly depended variables, and normalized all predictors.

</font>

<div class="columns-2">

**Four methods**  
 1. Linear Regression          
 2. Elasticnet Regression   
 3. Decision Tree   
 4. Boosted Ensemble  
 
 
**Tuning Method**  
 **-** 5-fold Cross Validation  
 **-** Root Mean Square Error  


 </div>  
  
**Tuned Parameters**  
 **-** Elasticnet Regression: *Penalty = 0.01, Mixture = 0.3*  
 **-** Decision Tree: *Cost Complexity = 0, Tree Depth = 10*  
 **-** Boosted Ensemble: *Learning Rate = 0.1, Tree Depth = 11*
 

 
## Outcome

```{r outcome graph, out.width= "65%", out.extra='style="float:right; padding:10px"'}
knitr::include_graphics("C:/Users/ojett/Documents/EC424/ec424project/project_markdown_files/figure-gfm/Prediction-2.png")
```

 **-** The boosted model performed the best on CV and test data! 
 
 **-** The decision tree's dramatic drop in performance is likely due to it being overfit to the training data.  
 
 **-** The elasticnet and regression models had similar errors on CV and test data; suggesting possibly similar models.  


## Sources  

 * Emissions by power plant for CO2, SO2, and NOx (2019)  
    https://www.eia.gov/electricity/data/emissions/   
 * Guide to data  
    https://www.eia.gov/electricity/data/guide/pdf/guide.pdf  
 * Heating days data  
    https://www.ncdc.noaa.gov/societal-impacts/redti/time-series/USA/dec/year-to-date  

**Contact:** ojetton@uoregon.edu
